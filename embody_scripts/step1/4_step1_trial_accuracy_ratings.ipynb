{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trial Level Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Function</b>: Calculates the classifier accuracy for each trial where subject also rates how well they paid attention to the specified task. \n",
    "<br>\n",
    "#### Output\n",
    "* trial_accuracy.csv (*trial-by-trial accuracies for subject*)\n",
    "<br>\n",
    "* ratings.csv (*trial-by-trial accuracies matched with ratings for subect*)\n",
    "<br>\n",
    "* all_subjects_rating.csv (*ratings files for all subjects in one*)\n",
    "<br>\n",
    "<br>\n",
    "* rating_level_accuracy.csv (*accuracy collapsed by rating with rating count (number of times the rating was entered*)\n",
    "* rating_level_accuracy_clean.csv (*same as above with rating count for trials >= 3 consecutive events*)\n",
    "<br>\n",
    "#### Within Subjects Correlation - All Conditions\n",
    "<br>\n",
    "* all_subjects_within_subj_corr_n33.csv (*trial accuracy by rating: R, p, & z values for each subject)\n",
    "<br>\n",
    "#### Within Subjects Correlation - By Condition\n",
    "<br>\n",
    "* trial accuracy by rating: R, p, & z values for each subject, separated by condition\n",
    "* all_subjects_within_subj_corr_n9_breath.csv\n",
    "* all_subjects_within_subj_corr_n6_self.csv\n",
    "* all_subjects_within_subj_corr_n9_sounds.csv\n",
    "* all_subjects_within_subj_corr_n9_feet.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "import scipy.io as sio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set analysis name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "analysis = \"phase1_demo\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Root, Regressor, and Eprime files directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "root_dir = \"/Path/to/EMBODY/files\"\n",
    "regressor_dir = \"%s/regressors\" % root_dir\n",
    "eprime_files = \"%s/eprime_files\" % root_dir "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up subjects & subject task orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subjects = [124]\n",
    "orders = ['order2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Necessary Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Import MATLAB File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def import_matlab_file(subj):\n",
    "    \"\"\"Input is subject number (int) to import subject's pretty_results_step1.mat file.\n",
    "       Output is pd DataFrame with block number & regressor accuracy (0 or 1).\"\"\"\n",
    "    \n",
    "    os.chdir(\"%s/%s/results/step1/%d\" % (root_dir, analysis, subj))\n",
    "    \n",
    "    pretty_results_step1 = sio.matlab.loadmat(\"pretty_results_step1.mat\")\n",
    "    pretty_results_step1 = pretty_results_step1[\"prettyResult\"][0]\n",
    "    \n",
    "    classCorrect = pd.Series(pretty_results_step1['classCorrect'][0][0])\n",
    "    \n",
    "    block = pd.Series(pretty_results_step1[\"block\"][0][0])\n",
    "    block_accuracy = pd.DataFrame({'block': block, 'classCorrect': classCorrect})\n",
    "    \n",
    "    return block_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Import EPrime Ratings File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def openTable(name):\n",
    "    \"\"\" Opens eprime file with subject ratings and returns in a format readable by Python\n",
    "\n",
    "        name: filename (example, openTable(\"embody_mvpa.txt\"))\n",
    "    \"\"\"\n",
    "    import asciitable\n",
    "\n",
    "    unicode = open(name).read().decode('utf16')\n",
    "    spliced = unicode[unicode.index(\"ExperimentName\"):]\n",
    "    names = spliced[spliced.index('\\n')-1:]\n",
    "    ascii = spliced.decode('ascii')\n",
    "    \n",
    "    return asciitable.read(ascii, numpy=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h4>Import regressor files matched for each task order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def import_regressor_files(order):\n",
    "    \"\"\"Input regressor order number (int).\n",
    "    \n",
    "        Returns a Pandas DataFrame with trial & condition for each TR in specified order.\n",
    "    \n",
    "        Input is integer: 1, 2, 3, 4\"\"\"\n",
    "    \n",
    "    # order_string = \"order%d\" % order\n",
    "    \n",
    "    os.chdir(\"%s/%s\" % (regressor_dir, order))\n",
    "    \n",
    "    # read file with regressor \n",
    "    regressors = sio.matlab.loadmat(\"regressors.mat\")\n",
    "    regressors = regressors[\"regressors\"]\n",
    "\n",
    "    regressors_df = pd.DataFrame(regressors)\n",
    "    regressors_df = regressors_df.transpose()\n",
    "    regressors_df[\"trial\"] = None\n",
    "\n",
    "    data = regressors_df.copy()\n",
    "    data[\"condition\"] = None\n",
    "    \n",
    "    ####INSERT CONDITION NAMES\n",
    "\n",
    "    for tup in data.itertuples():\n",
    "        \n",
    "        if tup[0] < (data.shape[0] - 1):\n",
    "            \n",
    "            # if sum of row is > 0 it represents an event, if sum of row == 0 it represents a break\n",
    "            row_sum = sum(tup[1:6])\n",
    "\n",
    "            if row_sum == 0:\n",
    "                data.iloc[tup[0], 5] = None\n",
    "                data.iloc[tup[0], 6] = \"break\"\n",
    "\n",
    "            elif tup[1] == 1:\n",
    "                data.iloc[tup[0], 6] = \"breath\"\n",
    "\n",
    "            elif tup[2] == 1:\n",
    "                data.iloc[tup[0], 6] = \"feet\"\n",
    "\n",
    "            elif tup[3] == 1:\n",
    "                data.iloc[tup[0], 6] = \"stop\"\n",
    "\n",
    "            elif tup[4] == 1:\n",
    "                data.iloc[tup[0], 6] = \"self\"\n",
    "\n",
    "            elif tup[5] == 1:\n",
    "                data.iloc[tup[0], 6] = \"sounds\"\n",
    "                                    \n",
    "    #### INSERT TRIAL NUMBERS\n",
    "\n",
    "    trial_number = 0\n",
    "\n",
    "    for tup in data.itertuples():\n",
    "        if tup[0] < (data.shape[0] - 1):\n",
    "            \n",
    "            # identify trial change\n",
    "            # if the event is a break and the next event is different from the current, increase trial number\n",
    "            if (data.iloc[tup[0], 6] != data.iloc[(tup[0] + 1), 6]) and data.iloc[tup[0], 6] == \"break\":\n",
    "                trial_number += 1\n",
    "            \n",
    "            # set trial number\n",
    "            data.iloc[tup[0], 5] = trial_number\n",
    "\n",
    "    data.iloc[len(data) - 1, 5] = data.iloc[(len(data) - 2), 5]\n",
    "\n",
    "    data = data[data[\"condition\"] != \"break\"]\n",
    "\n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    data = data[[\"trial\", \"condition\"]]\n",
    "        \n",
    "        \n",
    "    return data[:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Regressor Orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import regressor files for each of the four orders.\n",
    "\n",
    "order1_regressor = import_regressor_files(\"order1\")\n",
    "\n",
    "order2_regressor = import_regressor_files(\"order2\")\n",
    "\n",
    "order3_regressor = import_regressor_files(\"order3\")\n",
    "\n",
    "order4_regressor = import_regressor_files(\"order4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy_by_trial(subj, order):\n",
    "    \n",
    "    \"\"\"Input subject number and subject's regressor order as integers\n",
    "        E.g., accruacy_by_trial(124, 2) \n",
    "        \n",
    "        Returns dataframes with block/trial/condition and trial-by-trial accuracies.\"\"\"\n",
    "    \n",
    "    order_df = import_regressor_files(order)\n",
    "    \n",
    "    data = import_matlab_file(subj).merge(order_df, left_index=True, right_index=True)\n",
    "    trial_accuracy = data.groupby([\"trial\"])[\"classCorrect\"].mean()\n",
    "    trial_accuracy = pd.DataFrame(trial_accuracy)\n",
    "    trial_accuracy = trial_accuracy.reset_index()\n",
    "        \n",
    "    return data, trial_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_for_subj_ratings(subj, order):\n",
    "    \n",
    "    \"\"\"Input subject number and subject's regressor order as integers.\n",
    "        E.g., accruacy_by_trial(124, 2) \n",
    "    \n",
    "       Returns a dataframe with trial, block, trial accuracy, & condition with trials 40-end.\"\"\"\n",
    "    \n",
    "    condition = pd.DataFrame(accuracy_by_trial(subj, order)[0][[\"block\", \"trial\", \"condition\"]])\n",
    "    \n",
    "    # Join trial condition information with trial level accuracy data\n",
    "    trial_accuracy_plus_condition = accuracy_by_trial(subj, order)[1].merge(condition, how=\"right\", on=\"trial\")\n",
    "    \n",
    "    # reorder column names\n",
    "    trial_accuracy_plus_condition = trial_accuracy_plus_condition[[\"trial\", \"block\", \"classCorrect\", \"condition\"]]\n",
    "    \n",
    "    # Take data from trial 40 to last trial & reset index so it is sequential.\n",
    "    trial_40to78_acc = trial_accuracy_plus_condition.iloc[1080:]\n",
    "    trial_40to78_acc = trial_40to78_acc.reset_index(inplace=False, drop=True)\n",
    "    \n",
    "    # Keep only one row for each trial (the others are duplicates).\n",
    "    trial_40to78_acc = trial_40to78_acc.drop_duplicates()\n",
    "    trial_40to78_acc = trial_40to78_acc.reset_index(inplace=False, drop=True)\n",
    "    \n",
    "    return trial_40to78_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eprime_ratings_with_regressors(subj, order):\n",
    "    \n",
    "    \"\"\"import subject's eprime ratings file & merge with regressor & trial accuracy data.\"\"\"\n",
    "    \n",
    "    ### SET PATH TO EPRIME FILES\n",
    "    os.chdir('%s/%d' % (eprime_files, subj))\n",
    "    \n",
    "    eprime_file = openTable(\"embody_%s_%s.txt\" % (order, subj))\n",
    "    eprime_df = pd.DataFrame(eprime_file)\n",
    "    task_conditions = eprime_df[[\"Block\", \"Condition\", \"Duration\",\"BodyRatings3.RESP\"]]\n",
    "    task_conditions.loc[:, \"Duration\"] = pd.to_numeric(task_conditions.loc[:, \"Duration\"]) / 1000\n",
    "    task_conditions = task_conditions.reset_index()\n",
    "    \n",
    "    # index becomes trial number 1-end\n",
    "    task_conditions[\"index\"] = task_conditions[\"index\"] + 1\n",
    "    \n",
    "    # Remove baseline & Search conditions\n",
    "    task_conditions = task_conditions[~task_conditions[\"Condition\"].isin([\"Baseline\", \"Search\"])]\n",
    "    \n",
    "    # Drop rows with NaN values\n",
    "    task_conditions.loc[:, \"Block\"] = 0\n",
    "    task_conditions = task_conditions.dropna(how=\"any\")\n",
    "    \n",
    "    task_conditions = task_conditions.reset_index(inplace=False, drop=True)\n",
    "    task_conditions = task_conditions.drop([\"index\"], axis=1)\n",
    "    \n",
    "    merged_data = data_for_subj_ratings(subj, order).merge(task_conditions, left_index=True, right_index=True)\n",
    "    merged_data = merged_data[merged_data[\"Condition\"] != \"Stop\"]\n",
    "    \n",
    "    merged_data.loc[:, \"BodyRatings3.RESP\"] = pd.to_numeric(merged_data[\"BodyRatings3.RESP\"], downcast='float')\n",
    "    \n",
    "    # add block numbers to df\n",
    "    merged_data = merged_data.reset_index(inplace=False, drop=True)\n",
    "\n",
    "    for tup in merged_data.itertuples():\n",
    "        if (tup[0] + 1) in range(1, 14):\n",
    "            merged_data.iloc[tup[0], 5] = 4\n",
    "        elif (tup[0] + 1) in range(14, 27):\n",
    "            merged_data.iloc[tup[0], 5] = 5\n",
    "        elif (tup[0] + 1) in range(27, 39):\n",
    "            merged_data.iloc[tup[0], 5] = 6\n",
    "        else:\n",
    "            print(\"Index is out of range: %d\" % tup[0])\n",
    "    \n",
    "    return merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_nan_pearsons_r(rating_array, accuracy_array, subj):\n",
    "        \n",
    "        \"\"\"Count & Remove any nan (not a number) values before Pearson's R correlation.\"\"\"\n",
    "    \n",
    "        nan_count = 0 \n",
    "        \n",
    "        print(\"** Subject %d's data contains null values.\" % subj)\n",
    "        print(\"** Dropping null values before correlation.\")\n",
    "        \n",
    "        # check for number of nan values in body_ratings_np\n",
    "        for item in rating_array:\n",
    "            if np.isnan(item):\n",
    "                nan_count += 1\n",
    "                \n",
    "        print(\"** Removed %d null values.\" % nan_count)\n",
    "        print(\"\")\n",
    "        \n",
    "        rating_df = pd.DataFrame(rating_array)\n",
    "        accuracy_df = pd.DataFrame(accuracy_array)\n",
    "        \n",
    "        merge_df_clean_nan = rating_df.merge(accuracy_df, left_index=True, right_index=True)\n",
    "        merge_df_clean_nan = merge_df_clean_nan.dropna(axis=0, how=\"any\")\n",
    "        \n",
    "        rating_array = np.array(merge_df_clean_nan[\"0_x\"])\n",
    "        accuracy_array = np.array(merge_df_clean_nan[\"0_y\"])\n",
    "        \n",
    "        return (rating_array, accuracy_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Begin Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write 'trial_accuracy.csv' for each subject."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Writing 'trial_accuracy.csv' for...\")\n",
    "print(\"\")\n",
    "\n",
    "for i in range(len(subjects)):\n",
    "\n",
    "    print(\"subject %d\" % subjects[i])\n",
    "    \n",
    "    # calculate accuracy by trial\n",
    "    trial_accuracy = accuracy_by_trial(subjects[i], orders[i])[1]\n",
    "    \n",
    "    trial_accuracy.to_csv('%s/%s/results/step1/%d/trial_accuracy.csv' % (root_dir, analysis, subjects[i]), \n",
    "                          header=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Writing ratings.csv for each subject."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"writing 'ratings.csv' for...\")\n",
    "\n",
    "# all subject data for taking overall ratings mean\n",
    "all_subject_ratings = pd.DataFrame(columns=[\"classCorrect\", \"BodyRatings3.RESP\"])\n",
    "all_subject_ratings_breath = pd.DataFrame(columns=[\"classCorrect\", \"BodyRatings3.RESP\", \"condition\"])\n",
    "all_subject_ratings_self = pd.DataFrame(columns=[\"classCorrect\", \"BodyRatings3.RESP\", \"condition\"])\n",
    "\n",
    "\n",
    "for i in range(len(subjects)):\n",
    "\n",
    "    # match subject data with ratings data & write out ratings.csv for each subject\n",
    "    trial_40to78_acc = data_for_subj_ratings(subjects[i], orders[i])\n",
    "\n",
    "    # open eprime file\n",
    "    eprime_file = eprime_ratings_with_regressors(subjects[i], orders[i])\n",
    "\n",
    "    # write classifier & rating data to csv\n",
    "    ratings_out = eprime_file.loc[:, [\"trial\", \"classCorrect\", \"condition\", \"Duration\", \"BodyRatings3.RESP\"]]\n",
    "\n",
    "    to_append = ratings_out.loc[:, [\"classCorrect\", \"BodyRatings3.RESP\", \"condition\"]]\n",
    "    to_append_breath = to_append[to_append[\"condition\"] == \"breath\"]\n",
    "    to_append_self = to_append[to_append[\"condition\"] == \"self\"]\n",
    "\n",
    "    all_subject_ratings = all_subject_ratings.append(to_append)\n",
    "    all_subject_ratings_breath = all_subject_ratings_breath.append(to_append_breath)\n",
    "    all_subject_ratings_self = all_subject_ratings_self.append(to_append_self)\n",
    "    \n",
    "    print(\"subject %d\" % subjects[i])\n",
    "\n",
    "    ratings_out.to_csv(\"%s/%s/results/step1/%d/ratings.csv\" % (root_dir, analysis, subjects[i]),\n",
    "                       header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write out 'all_subject_ratings' dataframe to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_subject_ratings.to_csv('%s/%s/results/step1_compile/all_subjects_rating.csv' % (root_dir, analysis))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Within Subjects Correlations - All Condtions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fisher r to z transformation\n",
    "\n",
    "http://vassarstats.net/tabs_rz.html\n",
    "\n",
    "For any particular value of r, the Pearson product-moment correlation coefficient, this section will perform the Fisher r-to-z transformation according to the formula\n",
    "##### zr = (1/2)[loge(1+r) - loge(1-r)]\n",
    "\n",
    "If a value of N is entered (optional), it will also calculate the standard error of zr as\n",
    "##### SEzr = 1/sqrt[N-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create group dataframe for all subjects withins-subjects correlations\n",
    "all_subjects_within_subject_corr_n33 = pd.DataFrame(columns=[\"R\", \"p\"], index=subjects)\n",
    "\n",
    "for i in range(len(subjects)):\n",
    "\n",
    "    # read in ratings.csv for each subject\n",
    "    ratings = pd.read_csv(\"%s/%s/results/step1/%d/ratings.csv\" % (root_dir, analysis, subjects[i]))\n",
    "    \n",
    "    # create array for np arrays for pearsons r calculation\n",
    "    ratings_np = np.array(ratings[\"BodyRatings3.RESP\"])\n",
    "    accuracy_np = np.array(ratings[\"classCorrect\"])\n",
    "\n",
    "    # calculate pearsons r and p values for within-subjects trial accuracy vs rating\n",
    "    R, p = scipy.stats.pearsonr(ratings_np, accuracy_np)\n",
    "    \n",
    "    if np.isnan(R):\n",
    "        ratings_np, accuracy_np = remove_nan_pearsons_r(ratings_np, accuracy_np, subjects[i])\n",
    "        R, p = scipy.stats.pearsonr(ratings_np, accuracy_np)\n",
    "   \n",
    "        \n",
    "    # add r and p values for each subject to a complied \"all subjects within subjects corr\" dataframe \n",
    "    all_subjects_within_subject_corr_n33.loc[subjects[i]][\"R\"] = R\n",
    "    all_subjects_within_subject_corr_n33.loc[subjects[i]][\"p\"] = p\n",
    "    \n",
    "# calculate fisher r-to-z transformation\n",
    "all_subjects_within_subject_corr_n33[\"zr\"] = all_subjects_within_subject_corr_n33[\"R\"].map(lambda r: 0.5 * (np.log(1 + r) - np.log(1 - r)))\n",
    "\n",
    "# write result to csv\n",
    "all_subjects_within_subject_corr_n33.to_csv(\"%s/%s/results/step1_compile/all_subjects_within_subj_corr_n33.csv\" % (root_dir, analysis))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Within Subjects Correlations - By Condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculateWithinSubjectsCorrCondition(subj, condition):\n",
    "\n",
    "    # read in ratings file\n",
    "    ratings = pd.read_csv(\"%s/%s/results/step1/%d/ratings.csv\" % (root_dir, analysis, subj))\n",
    "\n",
    "    # isolate ratings by condition\n",
    "    ratings_condition = ratings[ratings[\"condition\"] == condition]\n",
    "\n",
    "    # create array for np arrays for pearsons r calculation\n",
    "    ratings_condition_np = np.array(ratings_condition[\"BodyRatings3.RESP\"])\n",
    "    accuracy_condition_np = np.array(ratings_condition[\"classCorrect\"])\n",
    "\n",
    "    # calculate pearsons r and p values for within-subjects trial accuracy vs rating\n",
    "    R, p = scipy.stats.pearsonr(ratings_condition_np, accuracy_condition_np)\n",
    "\n",
    "    if np.isnan(R):\n",
    "        ratings_condition_np, accuracy_condition_np = remove_nan_pearsons_r(ratings_condition_np, accuracy_condition_np, subj)\n",
    "        R, p = scipy.stats.pearsonr(ratings_condition_np, accuracy_condition_np)\n",
    "        \n",
    "    return R, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def condition_within_subject_corr(subject_list, condition):\n",
    "    \"\"\"Input subject numbers (list), condition (str).\n",
    "    \n",
    "        Returns dataframe with all subject's R, p, and zr values.\"\"\"\n",
    "    \n",
    "    # create empty output dataset\n",
    "    condition_within_subject_corr_df = pd.DataFrame(columns=[\"R\", \"p\"], index=subject_list)\n",
    "    \n",
    "    # calcuate R and p values for all subjects\n",
    "    for i in range(len(subject_list)):\n",
    "                \n",
    "        # calculate R & p values\n",
    "        R, p = calculateWithinSubjectsCorrCondition(subject_list[i], condition)\n",
    "        \n",
    "        # assign R & p values to output dataframe\n",
    "        condition_within_subject_corr_df.loc[subject_list[i], \"R\"] = R\n",
    "        condition_within_subject_corr_df.loc[subject_list[i], \"p\"] = p\n",
    "    \n",
    "    # calculate r to z transformation for all subjects\n",
    "    condition_within_subject_corr_df[\"zr\"] = condition_within_subject_corr_df[\"R\"].map(lambda r: 0.5 * (np.log(1 + r) - np.log(1 - r)))\n",
    "    \n",
    "    return condition_within_subject_corr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "breath_within_subject_corr_n9 = condition_within_subject_corr(subjects, \"breath\")\n",
    "breath_within_subject_corr_n9.to_csv(\"%s/%s/results/step1_compile/all_subjects_within_subj_corr_n9_breath.csv\" % (root_dir, analysis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "self_within_subject_corr_n6 = condition_within_subject_corr(subjects, \"self\")\n",
    "self_within_subject_corr_n6.to_csv(\"%s/%s/results/step1_compile/all_subjects_within_subj_corr_n6_self.csv\" % (root_dir, analysis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feet_within_subject_corr_n9 = condition_within_subject_corr(subjects, \"feet\")\n",
    "feet_within_subject_corr_n9.to_csv(\"%s/%s/results/step1_compile/all_subjects_within_subj_corr_n9_feet.csv\" % (root_dir, analysis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sounds_within_subject_corr_n9 = condition_within_subject_corr(subjects, \"sounds\")\n",
    "sounds_within_subject_corr_n9.to_csv(\"%s/%s/results/step1_compile/all_subjects_within_subj_corr_n9_sounds.csv\" % (root_dir, analysis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
